#try this later

from sklearn.model_selection import train_test_split, GridSearchCV

# Define the parameter grid
param_grid = {
    'solver': ['lbfgs', 'sgd', 'adam'],
    'learning_rate': ['constant', 'invscaling', 'adaptive'],
    'learning_rate_init': [0.001, 0.01, 0.1],
    'batch_size': [32, 64, 128],
    'momentum': [0.9, 0.95, 0.99],
    'early_stopping': [True, False],
    'max_iter': [1000, 2000]
}

# Create the MLPClassifier with the tuned hyperparameters
mlp = MLPClassifier(
    hidden_layer_sizes=(100, 50),
    activation='relu',
    alpha=0.1,
    random_state=42,
    verbose=True
)

# Create a scorer for F1 Score
f1_scorer = make_scorer(f1_score, average='weighted')

# Set up the GridSearchCV
grid_search = GridSearchCV(mlp, param_grid, cv=5, scoring=f1_scorer, n_jobs=-1)

# Fit the model with GridSearchCV to find the best parameters
grid_search.fit(X_train, y_train)

# Best parameters found
print("Best parameters found: ", grid_search.best_params_)

# Train the model with the best parameters on the full training data
best_mlp = grid_search.best_estimator_
best_mlp.fit(X_train, y_train)

# Predictions
predictions = best_mlp.predict(X_val)



# Define the model with the tuned hyperparameters
mlp = MLPClassifier(solver='sgd', learning_rate='constant', alpha=0.1,
                    hidden_layer_sizes=(100, 50), activation='relu', random_state=42, warm_start=True)

# Initialize lists to store scores and loss values
train_losses = []
cv_scores = []

# Define the number of epochs
epochs = 100

# Cross-validation setup
cv = StratifiedKFold(n_splits=5)
f1_scorer = make_scorer(f1_score, average='weighted')

# Loop over the number of epochs
for epoch in range(1, epochs + 1):
    mlp.set_params(max_iter=epoch)  # Increment the number of epochs
    mlp.fit(X_train, y_train)  # Fit the model on the training data
    
    # Record the training loss
    train_losses.append(mlp.loss_)
    
    # Calculate the cross-validation score
    cv_score = cross_val_score(mlp, X_train, y_train, cv=cv, scoring=f1_scorer).mean()
    cv_scores.append(cv_score)

# Plot the training loss and cross-validation score
plt.figure(figsize=(10, 6))
plt.plot(range(1, epochs + 1), train_losses, label='Training loss', color='blue')
plt.plot(range(1, epochs + 1), cv_scores, label='Cross-validation score', color='green')
plt.xlabel('Epochs')
plt.ylabel('Loss / F1 Score')
plt.title('Training Loss and Cross-Validation Score Curve for MLPClassifier')
plt.legend(loc='best')
plt.grid(True)
plt.show()

