import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.metrics import make_scorer, recall_score
from sklearn.neural_network import MLPClassifier

# Load the dataset
fetal_health_df = pd.read_csv('fetal_health.csv')

# Display the first few rows of the dataset
print(fetal_health_df.head())

# Check for missing values
missing_values = fetal_health_df.isnull().sum()
print("Missing values in each column:\n", missing_values)

# Define the numerical columns (all columns except 'fetal_health')
numerical_features = fetal_health_df.columns.difference(['fetal_health']).tolist()

# Define the preprocessing pipeline
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_features)
    ])

# Separate features and target
X = fetal_health_df.drop('fetal_health', axis=1)
y = fetal_health_df['fetal_health']

# Apply the preprocessing pipeline to the features
X_preprocessed = preprocessor.fit_transform(X)

# Check the class distribution of the target variable
class_distribution = y.value_counts(normalize=True) * 100
print("Class distribution (%):\n", class_distribution)

# Split the data into training and validation sets (80% training, 20% validation)
X_train, X_val, y_train, y_val = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42, stratify=y)



import matplotlib.pyplot as plt
from sklearn.model_selection import validation_curve
from sklearn.metrics import make_scorer, recall_score

# Define the parameter range for alpha
alpha_range = np.logspace(-3, 1, 30)

# Create a scorer for Recall
recall_scorer = make_scorer(recall_score, average='weighted')

# Validation curve for alpha
train_scores, valid_scores = validation_curve(
    MLPClassifier(solver='sgd', max_iter=2500, learning_rate='constant', hidden_layer_sizes=(100, 50), activation='relu', random_state=42),
    X_train, y_train,
    param_name='alpha',
    param_range=alpha_range,
    cv=5,
    scoring=recall_scorer,
    n_jobs=-1
)

# Calculate mean and standard deviation for training and validation scores
train_mean = np.mean(train_scores, axis=1)
train_std = np.std(train_scores, axis=1)
valid_mean = np.mean(valid_scores, axis=1)
valid_std = np.std(valid_scores, axis=1)

# Plot the validation curve
plt.figure(figsize=(10, 6))
plt.plot(alpha_range, train_mean, label='Training score', color='blue')
plt.plot(alpha_range, valid_mean, label='Cross-validation score', color='green')
plt.fill_between(alpha_range, train_mean - train_std, train_mean + train_std, alpha=0.2, color='blue')
plt.fill_between(alpha_range, valid_mean - valid_std, valid_mean + valid_std, alpha=0.2, color='green')
plt.xscale('log')
plt.title('Validation Curve for MLPClassifier (alpha)')
plt.xlabel('Alpha')
plt.ylabel('Recall Score')
plt.legend(loc='best')
plt.grid(True)
plt.show()



import matplotlib.pyplot as plt
from sklearn.model_selection import validation_curve
from sklearn.metrics import make_scorer, recall_score
from sklearn.neural_network import MLPClassifier

# Define the parameter range for hidden_layer_sizes
hidden_layer_sizes_range = [
    (50,), (100,), (150,), 
    (50, 50), (100, 50), (100, 100), (150, 100), 
    (50, 50, 50), (100, 100, 100), (150, 150, 150), 
    (50, 50, 50, 50), (100, 100, 100, 100), (150, 150, 150, 150), 
    (50, 50, 50, 50, 50), (100, 100, 100, 100, 100), (150, 150, 150, 150, 150),
    (50, 50, 50, 50, 50, 50), (100, 100, 100, 100, 100, 100), (150, 150, 150, 150, 150, 150)
]
hidden_layer_sizes_labels = [str(hls) for hls in hidden_layer_sizes_range]

# Create a scorer for Recall
recall_scorer = make_scorer(recall_score, average='weighted')

# Validation curve for hidden_layer_sizes
train_scores, valid_scores = validation_curve(
    MLPClassifier(solver='sgd', max_iter=3000, learning_rate='constant', alpha=0.1, activation='relu', random_state=42, verbose=True),
    X_train, y_train,
    param_name='hidden_layer_sizes',
    param_range=hidden_layer_sizes_range,
    cv=5,
    scoring=recall_scorer,
    n_jobs=-1
)

# Calculate mean and standard deviation for training and validation scores
train_mean = np.mean(train_scores, axis=1)
train_std = np.std(train_scores, axis=1)
valid_mean = np.mean(valid_scores, axis=1)
valid_std = np.std(valid_scores, axis=1)

# Plot the validation curve
plt.figure(figsize=(12, 8))
plt.plot(range(len(hidden_layer_sizes_range)), train_mean, label='Training score', color='blue')
plt.plot(range(len(hidden_layer_sizes_range)), valid_mean, label='Cross-validation score', color='green')
plt.fill_between(range(len(hidden_layer_sizes_range)), train_mean - train_std, train_mean + train_std, alpha=0.2, color='blue')
plt.fill_between(range(len(hidden_layer_sizes_range)), valid_mean - valid_std, valid_mean + valid_std, alpha=0.2, color='green')
plt.xticks(range(len(hidden_layer_sizes_labels)), hidden_layer_sizes_labels, rotation=45, ha='right')
plt.title('Validation Curve for MLPClassifier (hidden_layer_sizes)')
plt.xlabel('Hidden Layer Sizes')
plt.ylabel('Recall Score')
plt.legend(loc='best')
plt.grid(True)
plt.tight_layout()
plt.show()



import matplotlib.pyplot as plt
from sklearn.model_selection import validation_curve
from sklearn.metrics import make_scorer, recall_score
from sklearn.neural_network import MLPClassifier

# Define the parameter range for activation functions
activation_range = ['logistic', 'tanh', 'relu']

# Create a scorer for Recall
recall_scorer = make_scorer(recall_score, average='weighted')

# Validation curve for activation functions
train_scores, valid_scores = validation_curve(
    MLPClassifier(solver='sgd', max_iter=3000, learning_rate='constant', alpha=0.1, hidden_layer_sizes=(50, 50), random_state=42, verbose=True),
    X_train, y_train,
    param_name='activation',
    param_range=activation_range,
    cv=5,
    scoring=recall_scorer,
    n_jobs=-1
)

# Calculate mean and standard deviation for training and validation scores
train_mean = np.mean(train_scores, axis=1)
train_std = np.std(train_scores, axis=1)
valid_mean = np.mean(valid_scores, axis=1)
valid_std = np.std(valid_scores, axis=1)

# Plot the validation curve
plt.figure(figsize=(10, 6))
plt.plot(activation_range, train_mean, label='Training score', color='blue')
plt.plot(activation_range, valid_mean, label='Cross-validation score', color='green')
plt.fill_between(activation_range, train_mean - train_std, train_mean + train_std, alpha=0.2, color='blue')
plt.fill_between(activation_range, valid_mean - valid_std, valid_mean + valid_std, alpha=0.2, color='green')
plt.title('Validation Curve for MLPClassifier (activation)')
plt.xlabel('Activation Function')
plt.ylabel('Recall Score')
plt.legend(loc='best')
plt.grid(True)
plt.tight_layout()
plt.show()



from sklearn.model_selection import StratifiedKFold, cross_val_score
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import recall_score, make_scorer
import matplotlib.pyplot as plt
import numpy as np

# Define the model with the tuned hyperparameters
mlp = MLPClassifier(solver='sgd', max_iter=1, learning_rate='constant', alpha=0.1,
                    hidden_layer_sizes=(50, 50), activation='relu', warm_start=True, random_state=42)

# Initialize lists to store scores
train_scores = []
cv_scores = []

# Define the number of epochs
epochs = np.arange(1, 51)  # Reduced the number of epochs to 50

# Cross-validation setup
cv = StratifiedKFold(n_splits=3)  # Reduced the number of folds to 3

# Create a scorer for Recall
recall_scorer = make_scorer(recall_score, average='weighted')

# Loop over the number of epochs
for epoch in epochs:
    mlp.max_iter = epoch  # Set the current number of epochs
    mlp.fit(X_train, y_train)  # Fit the model on the training data
    
    # Calculate training score
    train_score = recall_score(y_train, mlp.predict(X_train), average='weighted')
    train_scores.append(train_score)
    
    # Calculate cross-validation score
    cv_score = cross_val_score(mlp, X_train, y_train, cv=cv, scoring=recall_scorer, n_jobs=-1).mean()
    cv_scores.append(cv_score)

# Plot the learning curve
plt.figure(figsize=(10, 6))
plt.plot(epochs, train_scores, label='Training score', color='blue')
plt.plot(epochs, cv_scores, label='Cross-validation score', color='green')
plt.xlabel('Epochs')
plt.ylabel('Recall Score')
plt.title('Learning Curve for MLPClassifier (Recall Score)')
plt.legend(loc='best')
plt.grid(True)
plt.show()



from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import train_test_split, cross_val_score

# Define the model with the tuned hyperparameters
mlp = MLPClassifier(solver='sgd', max_iter=1, learning_rate='constant', alpha=0.1,
                    hidden_layer_sizes=(100, 50), activation='relu', warm_start=True, random_state=42)

# Initialize lists to store scores
train_scores = []
cv_scores = []

# Define the number of epochs
epochs = np.arange(1, 101)

# Cross-validation setup
cv = StratifiedKFold(n_splits=5)

# Loop over the number of epochs
for epoch in epochs:
    mlp.max_iter = epoch  # Set the current number of epochs
    mlp.fit(X_train, y_train)  # Fit the model on the training data
    
    # Calculate training score
    train_score = f1_score(y_train, mlp.predict(X_train), average='weighted')
    train_scores.append(train_score)
    
    # Calculate cross-validation score
    cv_score = cross_val_score(mlp, X_train, y_train, cv=cv, scoring=f1_scorer).mean()
    cv_scores.append(cv_score)

# Plot the learning curve
plt.figure(figsize=(10, 6))
plt.plot(epochs, train_scores, label='Training score', color='blue')
plt.plot(epochs, cv_scores, label='Cross-validation score', color='green')
plt.xlabel('Epochs')
plt.ylabel('F1 Score')
plt.title('Learning Curve for MLPClassifier')
plt.legend(loc='best')
plt.grid(True)
plt.show()



